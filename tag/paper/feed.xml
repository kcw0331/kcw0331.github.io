<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://kcw0331.github.io/tag/paper/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://kcw0331.github.io/" rel="alternate" type="text/html" />
  <updated>2023-01-20T01:49:13+09:00</updated>
  <id>https://kcw0331.github.io/tag/paper/feed.xml</id>

  
  
  

  
    <title type="html">꿈을 향해 나아가자! | </title>
  

  
    <subtitle>창우의 아이티블로그</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Paper - RCNN(Review)</title>
      <link href="https://kcw0331.github.io/tag/paper-RCNN(Review)" rel="alternate" type="text/html" title="Paper - RCNN(Review)" />
      <published>2023-01-19T09:40:00+09:00</published>
      <updated>2023-01-19T09:40:00+09:00</updated>
      <id>https://kcw0331.github.io/tag/paper-RCNN(Review)</id>
      <content type="html" xml:base="https://kcw0331.github.io/tag/paper-RCNN(Review)">&lt;p&gt;&lt;span class=&quot;table-of-contents-list&quot;&gt;Paper Review 구성 목록은 아래와 같이 되어있습니다. &lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;table-of-contents-list&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;./paper-RCNN(Review)&quot;&gt;RCNN - Review&lt;/a&gt;&lt;/li&gt;
&lt;!--    &lt;li&gt;&lt;a href=&quot;./msai-1weeks(2)&quot;&gt;Msai - 1주차(2)&lt;/a&gt;&lt;/li&gt;--&gt;
&lt;!--    &lt;li&gt;&lt;a href=&quot;./msai-1weeks(3)&quot;&gt;Msai - 1주차(3)&lt;/a&gt;&lt;/li&gt;--&gt;
&lt;!--    &lt;li&gt;&lt;a href=&quot;./msai-pokerimageclassification&quot;&gt;Msai - 포커이미지 분류&lt;/a&gt;&lt;/li&gt;--&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;-r-cnn-review-&quot;&gt;&lt;center&gt; R-CNN Review &lt;/center&gt;&lt;/h1&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ganghee-lee.tistory.com/35&quot;&gt;참고 블로그 링크1&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://velog.io/@whiteamericano/R-CNN-%EC%9D%84-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90&quot;&gt;참고 블로그 링크2&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;1) classification
&lt;br /&gt;
   2) Object Detection
&lt;br /&gt;
   3) Image Segmentation
&lt;br /&gt;
   4) Visual Relationship&lt;/p&gt;

&lt;p&gt;CV(Computer Vision)은 위에 4가지로 분류가 된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Classification : Single object에 대해서 object의 클래스를 분류하는 문제&lt;/li&gt;
  &lt;li&gt;Classification + Localization : Single Obect에 대해서 Object의 위치를 Bounding Box로 찾고 (Localization) + 클래스를 분류하는 것(Classification)&lt;/li&gt;
  &lt;li&gt;Object Detection : Multiple objects에서 각각의 object에 대해서 Classification + Localization을 수행하는 것&lt;/li&gt;
  &lt;li&gt;Instance Segmentation : Object Detection과 유사하지만, 다른점은 object의 위치를 bounding box가 아닌 실제 edge로 찾는 것&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-1-2-stage-detector&quot;&gt;1-1). 2-Stage-Detector&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/2-stage-detector.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/2-stage-detector2.jpg&quot; /&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;R-CNN계열(R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN etc.)&lt;/li&gt;
  &lt;li&gt;2-Stage Detector는 Region Proposal network등과 같은 알고리즘 및 네트워크를 통해 객체가 있을 영역(Region of Interest, RoI)을 추출해낸다. 이후 Classification과 Localization을 진행한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-2-1-stage-detector&quot;&gt;1-2). 1-Stage-Detector&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/1-stage-detector.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/1-stage-detector2.jpg&quot; /&gt;
&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;YOLO, SSD계열(SSD, RetinaNet, RefineDet etc.)&lt;/li&gt;
  &lt;li&gt;1-Stage Detector는 RoI를 추출하지 않고 전체 이미지에 대해 Convolution Network로 Classification과 Localization을 진행한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://ganghee-lee.tistory.com/34&quot;&gt;참고 사진1&lt;/a&gt;
&lt;a href=&quot;https://ganghee-lee.tistory.com/35&quot;&gt;참고 사진2&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-3-2-stage-detector와-1-stage-detector의-장단점&quot;&gt;1-3). 2-Stage-Detector와 1-Stage-Detector의 장단점&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;2-Stage-Detector장점 &amp;amp; 단점
    &lt;ul&gt;
      &lt;li&gt;속도가 빠르지만 정확도가 떨어진다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;1-Stage-Detector장점 &amp;amp; 단점
    &lt;ul&gt;
      &lt;li&gt;정확도가 높지만 속도가 느리다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-r-cnn&quot;&gt;2. R-CNN&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/R-CNN.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ganghee-lee.tistory.com/35&quot;&gt;참고 사진2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;R-CNN은 위에서 보았던, 2-Stage-Detector라고 볼 수 있다.
&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;R-CNN의 진행과정은 다음과 같다.
    &lt;ol&gt;
      &lt;li&gt;이미지 입력&lt;/li&gt;
      &lt;li&gt;Selective search알고리즘을 사용하여 대략 2,000개의 regional proposal output추출 후 동일한 input size를 만들기 위해 warp해준다.(마지막 FC layer에서 input size는 고정이기 때문에 Convolution Layer에 대한 output size도 동일해야 해서 input size에서 부터 동일한 사이즈를 넣어주어야 한다.)&lt;/li&gt;
      &lt;li&gt;대략 2,000개의 warped image를 CNN모델에 투입&lt;/li&gt;
      &lt;li&gt;각각의 Convolution 결과를 기반으로 Classification(SVM)을 진행 후 결과 추출&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-1-region-proposal&quot;&gt;2-1). Region Proposal&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Sliding window(이미지의 맨 위에서 부터 쭉 읽으면서 탐색)은 탐색이 너무 느리고 비효율적이여서 Selective search알고리즘을 사용하게 됨&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;selective-search&quot;&gt;Selective search&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/selectivesearch.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ganghee-lee.tistory.com/35&quot;&gt;참고 사진2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Selective search의 진행과정
    &lt;ol&gt;
      &lt;li&gt;색상, 질감, 영역크기 등을 이용하여 Non-object-based segmentation수행&lt;/li&gt;
      &lt;li&gt;Bottom-up 방식으로 small segmented areas들을 합쳐서 더 큰 segmented areas를 만듦&lt;/li&gt;
      &lt;li&gt;두번째를 반복을 통해 최종적으로 대략 2,000개의 region proposal을 생성&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;* 주의사항: CNN에 넣기 전에 같은 사이즈로 warp해주어야 한다.&lt;/p&gt;

&lt;h3 id=&quot;2-2-cnn&quot;&gt;2-2). CNN&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/alexnetblockdiagram.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96&quot;&gt;참고 사진3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;CNN은 AlexNet의 구조를 사용하며 Resion proposal로 부터 4096차원의 특징 벡터를 뽑아낸 후 고정된 길이의 특징 벡터를 만들어낸다.&lt;/p&gt;

&lt;h3 id=&quot;2-3-svm&quot;&gt;2-3). SVM&lt;/h3&gt;

&lt;p&gt;softmax보다 SVM이 좋은 성능을 보여 SVM을 사용하였다고 한다.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/svm.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Support_vector_machine#/media/File:SVM_margin.png&quot;&gt;참고 사진4&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SVM은 CNN(AlexNet)으로 부터 추출된 각각의 특징 벡터들의 점수를 클래스별로 계산 후 객체인지 아닌지, 어떤 객체인지 등을 판별하는 역할을 하는 Classifier이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-4-bounding-box-regression&quot;&gt;2-4). Bounding Box Regression&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Bounding Box Regression은 처음에 y로 줬던 레이블과, CNN을 통과해서 나온 Bounding Box, 이 두 가지의 차이를 구해서 차이를 줄이도록 조정하는 선형회귀 모델 절차&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;/assets/built/images/paper/boundingbox.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://velog.io/@whiteamericano/R-CNN-%EC%9D%84-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90&quot;&gt;참고 사진5&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위 그림에서 P가 처음에 region proposal을 통해서 제안된 Bounding Box이고, G는 Ground Truth Bounding Box(정답 박스) 여기서 P를 정답 G에 맞추도록 transform 하는 것을 학습하는 것이 바로 Bounding Box Regression의 목표&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-정리&quot;&gt;3. 정리&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;이미지 하나의 임의의 영역들로 잘게 잘라서 merge 하고 warping 한 후,&lt;/li&gt;
  &lt;li&gt;CNN의 input으로 통과하여 Feature vecture를 추출하고,&lt;/li&gt;
  &lt;li&gt;적용된 label들을 이용해 SVM 분류와 Bounding Box Regression을 수행해서 영역 위치까지 예측을 하게 되는 모델이 바로 R-CNN&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>kcw0331</name>
        
        
      </author>

      

      
        <category term="paper" />
      

      
        <summary type="html">Paper Review 구성 목록은 아래와 같이 되어있습니다. RCNN - Review</summary>
      

      
      
    </entry>
  
</feed>
